{"posts":[{"title":"Introduction to Plasma","text":"Our Universe is made of 69% dark energy, 27% dark matter, 1% normal matter. What is plasma?Plasma is also called the “fourth state of matter”. Solid is heated to become a liquid, liquid is heated to become a gas.Upon further heating, the gas is ionized into a plasma. Since plasma usually exists only in a vacuum, we need to pump the air out of a vacuum chamber in the laboratory. The Definition of Plasma A plasma is a quasineutral gas of charged and neutral particles which exhibits collective behavior. The Coulomb force between A and B diminishes as 1/r^2. However, for a given solid angle($\\Delta$r/r = constant), the volume of plasma in B that can affect A increases as r^3. The Saha Equation\\frac{n_i}{n_n}\\approx2.4\\times10^{21}\\frac{T^{3/2}}{n_i}e^{-U_i/KT}n_i\\ is\\ the\\ density\\ of\\ ionized\\ atomsn_n\\ is\\ the\\ density\\ of\\ neutral\\ atomsK\\ is\\ Boltzmann's\\ constantU_i\\ is\\ the\\ ionization\\ energy\\ of\\ the\\ gasPhysical meaning When temperature is raising, the whole value is increasing exponentially with U_i/KT. The higher value of n_i, the lower recombination rate of ionized atoms. The Maxwellian DistributionThe one-dimensional Maxwellian distributionf(u)=Aexp(-\\frac{1}{2}mu^2/KT)fdu\\ is\\ the\\ number\\ of\\ particles\\ per\\ m^3\\ with\\ velocity\\ between\\ u\\ and\\ u+du\\frac{1}{2}mu^2\\ is\\ the\\ kinetic\\ energyBoltzmann’s constant KK=1.38\\times10^{-23}J/^{\\circ}KThe particles density nn=\\int_{-\\infty}^{\\infty}f(u)duThe constant A is related to the density nA=n(\\frac{m}{2\\pi KT})^{1/2} The average kinetic energy is $\\frac{1}{2}KT$ The three-dimensional Maxwellian distributionf(u,v,w)=A_3exp[-\\frac{1}{2}m(u^2+v^2+w^2)/KT] Reference BookIntroduction to Plasma Physics and Controlled Fusion by Francis F. Chen","link":"/2023/01/12/Introduction%20to%20Plasma/"},{"title":"Single Particle Motions","text":"Uniform E and B Fields The conditions: E = 0 The equation of motionm\\frac{dv}{dt}=q\\mathbf{v}\\times\\mathbf{B}Cyclotron frequency\\omega_c\\equiv\\frac{\\lvert q\\rvert\\mathbf{B}}{m} v_x=v_\\perp e^{i\\omega_c t}v_y=\\pm iv_\\perp e^{i\\omega_c t} combine The Larmor radiusr_L\\equiv\\frac{v_\\perp}{\\omega_c}=\\frac{mv_\\perp}{\\lvert q\\rvert\\mathbf{B}}we get x-x_0=r_Lsin\\omega_c ty-y_0=\\pm r_L cos\\omega_c t guiding center (x_0, y_0) plasmas are diamagnetic The conditions: finite E The equation of motionm\\frac{d\\mathbf v}{dt}=q(\\mathbf E+\\mathbf v\\times\\mathbf B) v_x=v_\\perp e^{i\\omega_c t}v_y=\\pm iv_\\perp e^{i\\omega_c t}-\\frac{\\mathbf E_x}{\\mathbf B} The usual circular Larmor gyration A drift of the guiding center The three-dimensional orbit in space is therefore a slanted helix with changing pitch. The conditions: gravitational field \\mathbf v_g=\\frac{m}{q}\\frac{\\mathbf g\\times\\mathbf B}{\\mathbf B^2} The magnitude of v_g is usually negligible But an effective gravitational force due to centrifugal force is not negligible Reference BookIntroduction to Plasma Physics and Controlled Fusion by Francis F. Chen","link":"/2023/01/12/Single%20Particle%20Motions/"},{"title":"Anaconda Command","text":"Anaconda Prompt OperationCreate new environment conda create - -name environment pakage conda create - -name python3 python=3.8 Activate environment conda activate environment Exit environment deactivate environment Delete environment conda remove -n environment - -all Copy environment conda create -n environment - -clone existing_environment View environment information conda info -econda env listconda info - -envs View python version python -V Install package conda install package View package information conda search package Install package in a specify environment conda install -n environment package Update package in a specify environment conda update -n environment package Delete package in a specify environment conda remove -n environment package View the installed packages in the current environment conda list View the installed packages in a specify environment conda list -n environment","link":"/2023/01/12/Anaconda%20Command/"},{"title":"Image Formation","text":"2D points\\mathbf x=(x,y)\\in\\textit R^2\\mathbf x=\\begin{bmatrix} x \\\\ y \\end{bmatrix}homogeneous vector \\mathbf{\\tilde x}\\mathbf{\\tilde x}=(\\tilde x,\\tilde y,\\tilde w)\\in\\textit P^2 2D projective space \\textit P^2=\\textit R^3-(0,0,0) inhomogeneous vector \\mathbf{\\overline x}\\mathbf{\\tilde x}=\\tilde w(x,y,1)=\\tilde w\\mathbf{\\overline x} Reference BookComputer Vision: Algorithms and Applications by Richard Szeliski","link":"/2023/01/13/Image%20Formation/"},{"title":"GNN Paper","text":"Review Graph Neural Networks: A Review of Methods and Applications, 2018 Deep Learning on Graphs: A Survey, 2018 Relationanl Inductive Biases, Deep Learning, and Graph Neural Networks, 2018 Geometric Deep Learning: Going beyond Euclidean data, 2017 Computational Capabilities of Graph Neural Networks, 2009 Neural Message Passing for Quantum Chemistry, 2017 Non-local Neural Networks, 2018 The Graph Neural Network Model, 2009 Model A new model for learning in graph domains, 2005 Graph Neural Networks for Ranking Web Pages, 2005 Gated Graph Sequence Neural Networks, 2016 Geometric deep learning on graphs and manifolds using mixture model cnns, 2017 Spectral Networks and locally Connected Networks on Graphs, 2014 Deep Convolutional Networks on Graph-Structure Data, 2015 Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, 2016 Learning Convolutional Neural Networks for Graphs, 2016 Semi-Supervised Classification with Graph Convolutional Networks, 2017 Graph Attention Networks, 2018 Application Discovering objects and their relations from entanglrd scene representations, 2017 A simple neural network module for relational reasoning, 2017","link":"/2023/01/14/GNN%20Paper/"},{"title":"Graph Neural Networks - A Review of Methods and Applications","text":"AbstractGraph neural networks are neural models that capture the dependence of graphs via message passing between the nodes of graphs. propose a general design pipeline for GNN models discuss the variants of each component systematically categorize the applications propose four open problems for future research IntroductionGraphs can be used across various areas social networks Graph Convolutional Networks with Markov Random Field Reasoning for Social Spammer Detection, 2020 natural science Graph Networks as Learnable Physics Engines for Inference and Control, 2018 Interaction Networks for Learning about Objects, Relations and Physics, 2016 protein-protein interaction networks Protein Interface Prediction using Graph Convolutional Networks, 2017 knowledge graphs Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach, 2017 other research areas Learning Combinatorial Optimization Algorithms over Graphs, 2017 The fundamental motivations of graph neural networks Recursive Neural Networks are first utilized on directed acyclic graphs Supervised neural networks for the classification of structures,1997 A general framework for adaptive processing of data structures, 1998 Recurent Neural Networks and Feedforward Neural Networks The Graph Neural Network Model, 2009 Neural Network for Graphs: A Contextual Constructive Approach, 2009 CNNs result in the rediscovery of GNNs Gradient-based learning applied to document recognition, 1998 the new era of deep learning Deep learning, 2015 geometric deep learning Geometric deep learning: going beyond Euclidean data, 2017 graph representation learning A Survey on Network Embedding, 2017Representation Learning on Graphs: Methods and Applications, 2017Network Representation Learning: A Survey, 2017A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications, 2017Graph embedding techniques, applications, and performance: A survey,2018 word representations Efficient Estimation of Word Representations in Vector Space, 2013 DeepWalk DeepWalk: Online Learning of Social Representations, 2014 SkipGram model Efficient Estimation of Word Representations in Vector Space, 2013 node2vec node2vec: Scalable Feature Learning for Networks, 2016 LINE LINE: Large-scale Information Network Embedding, 2015 TADW Network representation learning with rich text information, 2015 drawbacks First, no parameters are shared between nodes in the encoder, which leads to computationally inefficiency, since it means the number of parameters grows linearly with the number of nodes. Second, the direct embedding methods lack the ability of generalization, which means they cannot deal with dynamic graphs or generalize to new graphs. several comprehensive reviews on graph neural networks Geometric deep learning: going beyond Euclidean data, 2017Graph convolutional networks: a comprehensive review, 2019 the most up-to-date survey papers on GNNs Deep Learning on Graphs: A Survey, 2018A Comprehensive Survey on Graph Neural Networks, 2019Machine Learning on Graphs: A Model and Comprehensive Taxonomy, 2020 several surveys focusing on some specific graph learning fields adversarial learning methods on graphs Adversarial Attack and Defense on Graph Data: A Survey, 2018A Survey of Adversarial Learning on Graphs, 2020 a review over graph attention models Attention Models in Graphs: A Survey, 2018 heterogeneous graph representation learning Heterogeneous Network Representation Learning: Survey, Benchmark, Evaluation, and Beyond existing GNN models for dynamic graphs Modeling Complex Spatial Patterns with Temporal Features via Heterogenous Graph Embedding Networks, 2020 graph embeddings methods for combinatorial optimization. Graph Embedding for Combinatorial Optimization: A Survey contributions We provide a detailed review over existing graph neural network models. We present a general design pipeline and discuss the variants of each module. We also introduce researches on theoretical and empirical analyses of GNN models. We systematically categorize the applications and divide the applications into structural scenarios and non-structural scenarios. We present several major applications and their corresponding methods for each scenario. We propose four open problems for future research. We provide a thorough analysis of each problem and propose future research directions. Reference PaperGraph Neural Networks: A Review of Methods and Applications, 2018","link":"/2023/01/14/Graph%20Neural%20Networks%20-%20A%20Review%20of%20Methods%20and%20Applications/"},{"title":"Fusion","text":"Thermonuclear Fusion heat the deuterium-tritium fuel to a sufficienly high temperature Necessary temperature around 10keV, about 100 million degrees centigrade In a tokamak the plasma particles are confined to a toroidal region by a magnetic field, being held by the field in small gyrating orbits. Energy required for ignition\\hat n\\tau_E\\hat T>5\\times10^{21}m^{-3}sKeV\\hat n\\ is\\ the\\ peak\\ ion\\ density\\ in\\ the\\ plasma\\hat T\\ is\\ the\\ peak\\ temperature\\ in\\ the\\ plasma\\tau_E\\ is\\ the\\ energy\\ confinement\\ time The nuclei of deuterium and tritium fuse to produce an alpha particle with the release of a neutron \\begin{aligned} _1D^2\\ \\ \\ \\ \\ \\ +\\ \\ \\ \\ \\ \\ _1T^3\\longrightarrow _2H&e^4\\ \\ \\ \\ \\ \\ \\ \\ +&_0n^1\\\\ &| &| \\\\ &35MeV\\ \\ + &&141MeV=176MeV \\end{aligned} Reference BookTokamaks by John Wesson","link":"/2023/01/14/Fusion/"},{"title":"Creation and Annihilation Operators for Identical Particles","text":"General formalismThe state space of a system of N distinguishable particles \\varepsilon_N=\\varepsilon_1(1)\\otimes\\varepsilon_1(2)\\otimes..\\otimes\\varepsilon_1(N) The space of the completely symmetric states for bosons \\varepsilon_S(N) The projectors S_N=\\frac{1}{N!}\\sum_\\alpha P_\\alpha The space of the completely antisymmetric states for fermions \\varepsilon_A(N) The projectors A_N=\\frac{1}{N!}\\sum_\\alpha\\varepsilon_\\alpha P_\\alpha The P_\\alpha is the N! permutation operators for the N particles The \\varepsilon_\\alpha is the parity of P_\\alpha The subscript \\alpha distinguishes the different permutations of the N particles, and therefore take N! different values Fock states for identical bosons |n_i,n_j,..,n_l,..\\rangle\\\\=cS_N|1:u_i;2:u_i;..;n_i:u_i;\\ \\ n_i+1:u_j;..n_i+n_j:u_j;..\\rangle The subscripts i, j, k, l, ..denote different basis vectors {|u_i\\rangle} of the state space \\varepsilon_1 of a single particle","link":"/2023/01/15/Creation%20and%20Annihilation%20Operators%20for%20Identical%20Particles/"},{"title":"Unique Factorization","text":"The prime number theory\\lim_{x\\to\\infty}\\frac{\\pi(x)}{x/\\ln(x)}=1\\pi(x)\\ is\\ the\\ number\\ of\\ primes\\ between\\ 1\\ and\\ xLemma 1Every nonzero integer can be written as a product of primes. Theorem 1For every nonzero integer n there is a prime factorization n=(-1)^{\\epsilon(n)} \\prod_{p}p^{a(p)}with the exponents uniquely determined by n. a(p)=ord_{p}nLemma 2Ifa,b\\in \\mathbb{Z} and b&gt;0, there exist q,r\\in\\mathbb{Z} such that a=qb+r with 0\\leq r","link":"/2023/01/16/Unique%20Factorization/"}],"tags":[],"categories":[{"name":"PLASMA","slug":"PLASMA","link":"/categories/PLASMA/"},{"name":"CV","slug":"CV","link":"/categories/CV/"},{"name":"TOKAMAKS","slug":"TOKAMAKS","link":"/categories/TOKAMAKS/"},{"name":"QUANTUM MECHANICS","slug":"QUANTUM-MECHANICS","link":"/categories/QUANTUM-MECHANICS/"},{"name":"ARITHMETIC","slug":"ARITHMETIC","link":"/categories/ARITHMETIC/"}],"pages":[]}